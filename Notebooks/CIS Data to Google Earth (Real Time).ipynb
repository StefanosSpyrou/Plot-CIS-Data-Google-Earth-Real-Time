{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CIS Data to Google Earth (Real Time)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a48fe114014d2f27"
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO: Include shorted status in exception report  \n",
    "# TODO: Delete (250V: Range from Comments) \n",
    "# TODO: Go through and add/review comments\n",
    "# TODO: Find more ways to optimize code\n",
    "# TODO: Split lines of code to more readable format"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T22:07:03.888570Z",
     "start_time": "2025-08-11T22:07:03.886557Z"
    }
   },
   "id": "c75af61d5de8ba26",
   "outputs": [],
   "execution_count": 496
  },
  {
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# --- Standard Library ---\n",
    "from collections import OrderedDict\n",
    "from dataclasses import dataclass, field, replace\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import socket\n",
    "import time\n",
    "\n",
    "# --- Scientific / Stats ---\n",
    "import scipy.stats as stats\n",
    "\n",
    "# --- Data Handling ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "\n",
    "# --- File Format ---\n",
    "import simplekml\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment, Border, Font, Side\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "# --- Geospatial ---\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# --- Pandas Settings ---\n",
    "pd.options.mode.chained_assignment = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.782481Z",
     "start_time": "2025-08-11T21:12:26.779435Z"
    }
   },
   "id": "97c56b5084f08151",
   "outputs": [],
   "execution_count": 448
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.786173Z",
     "start_time": "2025-08-11T21:12:26.784454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Measuring execution time\n",
    "start_time = time.time()"
   ],
   "id": "881862e48864f483",
   "outputs": [],
   "execution_count": 449
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration\n",
   "id": "93d7c14706287719"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.796719Z",
     "start_time": "2025-08-11T21:12:26.795010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CONFIG SETTINGS\n",
    "SELECTED_CONFIG = 'KM'\n",
    "\n",
    "# COLORBLIND FRIENDLY COLOR SCHEME\n",
    "COLORBLIND_MODE = False"
   ],
   "id": "57828796c294c552",
   "outputs": [],
   "execution_count": 450
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataclass",
   "id": "e3bb63bf6d4fac8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.817295Z",
     "start_time": "2025-08-11T21:12:26.811870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    # --- Basic Settings ---\n",
    "    CLIENT: str = \"Kinder Morgan\"\n",
    "    PLOT_3D: bool = True\n",
    "    DATA_VISIBILITY: bool = True\n",
    "    COLOR_SCHEME: int = 0\n",
    "    REVERSE: bool = False\n",
    "\n",
    "    # --- GPS Cutoffs ---\n",
    "    LOWER_CUTOFF: int = 1\n",
    "    UPPER_CUTOFF: int = 3\n",
    "\n",
    "    # --- Elevation Scaling ---\n",
    "    SCALE_FACTOR: float = 117.64705882352942\n",
    "    SCALE_PCM: float = 100 / 3\n",
    "    SCALE_PCM_PERCENT: float = 50\n",
    "\n",
    "    # --- Icon Scale ---\n",
    "    ICON_SCALE: float = 0.2\n",
    "\n",
    "    # --- Potential Thresholds ---\n",
    "    POTENTIAL_850 = -0.85\n",
    "    POTENTIAL_1200 = -1.2\n",
    "\n",
    "    # --- Icon URLs (to be set in __post_init__) ---\n",
    "    ICON_ON: str = field(init=False)\n",
    "    ICON_OFF: str = field(init=False)\n",
    "    ICON_NATIVE: str = field(init=False)\n",
    "    ICON_1200: str = field(init=False)\n",
    "    ICON_850: str = field(init=False)\n",
    "    ICON_COMMENTS: str = field(init=False)\n",
    "    ICON_ACVG: str = field(init=False)\n",
    "    ICON_PCM: str = field(init=False)\n",
    "    ICON_PCM_PERCENT: str = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Default (0)\n",
    "        icons = {\n",
    "            0: {\n",
    "                'ICON_ON': 'https://img.icons8.com/ios-filled/50/FC9CFF/filled-circle.png',\n",
    "                'ICON_OFF': 'https://img.icons8.com/ios-filled/50/00FF00/filled-circle.png',\n",
    "                'ICON_NATIVE': 'https://img.icons8.com/ios-filled/50/175082/filled-circle.png',\n",
    "                'ICON_1200': 'https://img.icons8.com/ios-filled/50/7950F2/filled-circle.png',\n",
    "                'ICON_850': 'https://img.icons8.com/ios-filled/50/F25081/filled-circle.png',\n",
    "            },\n",
    "            1: {\n",
    "                'ICON_ON': 'https://img.icons8.com/ios-filled/50/3D8D7A/filled-circle.png',\n",
    "                'ICON_OFF': 'https://img.icons8.com/ios-filled/50/FFFACD/filled-circle.png',\n",
    "                'ICON_NATIVE': 'https://img.icons8.com/ios-filled/50/FFF6DA/filled-circle.png',\n",
    "                'ICON_1200': 'https://img.icons8.com/ios-filled/50/2D336B/filled-circle.png',\n",
    "                'ICON_850': 'https://img.icons8.com/ios-filled/50/A94A4A/filled-circle.png',\n",
    "            },\n",
    "            2: {\n",
    "                'ICON_ON': 'https://img.icons8.com/ios-filled/50/87FF00/filled-circle.png',\n",
    "                'ICON_OFF': 'https://img.icons8.com/ios-filled/50/0079F7/filled-circle.png',\n",
    "                'ICON_NATIVE': 'https://img.icons8.com/ios-filled/50/FFF6DA/filled-circle.png',\n",
    "                'ICON_1200': 'https://img.icons8.com/ios-filled/50/00FFD4/filled-circle.png',\n",
    "                'ICON_850': 'https://img.icons8.com/ios-filled/50/FFFFFF/filled-circle.png',\n",
    "            }\n",
    "        }\n",
    "\n",
    "        selected = icons.get(self.COLOR_SCHEME, icons[0])  # fallback to 0\n",
    "        self.ICON_ON = selected['ICON_ON']\n",
    "        self.ICON_OFF = selected['ICON_OFF']\n",
    "        self.ICON_NATIVE = selected['ICON_NATIVE']\n",
    "        self.ICON_1200 = selected['ICON_1200']\n",
    "        self.ICON_850 = selected['ICON_850']\n",
    "\n",
    "        # Shared across all schemes\n",
    "        self.ICON_COMMENTS = 'https://img.icons8.com/ultraviolet/80/000000/comments.png'\n",
    "        self.ICON_ACVG = 'https://img.icons8.com/material-rounded/50/6BFF00/sine.png'\n",
    "        self.ICON_PCM = 'https://img.icons8.com/ios-filled/50/FFFFFF/lightning-bolt--v1.png'\n",
    "        self.ICON_PCM_PERCENT = (\n",
    "            'https://img.icons8.com/fluency-systems-regular/50/FFFFFF/percentage-circle.png'\n",
    "        )"
   ],
   "id": "288561cb90f38208",
   "outputs": [],
   "execution_count": 451
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Presets",
   "id": "6343c52d82ded7c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.868318Z",
     "start_time": "2025-08-11T21:12:26.866407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "KM = Config(CLIENT='Kinder Morgan')\n",
    "KM_1 = Config(CLIENT='Kinder Morgan', COLOR_SCHEME=1)\n",
    "ENB = Config(CLIENT='Enbridge')"
   ],
   "id": "1dbe5d15b56d23b2",
   "outputs": [],
   "execution_count": 452
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.872056Z",
     "start_time": "2025-08-11T21:12:26.870236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Config map\n",
    "config_map = {\n",
    "    'KM': KM,\n",
    "    'KM_1': KM_1,\n",
    "    'ENB': ENB,\n",
    "}\n",
    "\n",
    "# Select config (Default = KM)\n",
    "config = config_map.get(SELECTED_CONFIG, KM)\n",
    "\n",
    "# Colorblind mode\n",
    "if COLORBLIND_MODE:\n",
    "    config = replace(config, COLOR_SCHEME=2)"
   ],
   "id": "d333670f26b80cbb",
   "outputs": [],
   "execution_count": 453
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function Definitions",
   "id": "fe98484c85e7b442"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exception Report Dataframe",
   "id": "d5e13ea41ed77702"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.890911Z",
     "start_time": "2025-08-11T21:12:26.887521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exception_report_df(\n",
    "        export_name: str,\n",
    "        *,\n",
    "        potential_col: str,\n",
    ") -> tuple[pd.DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Load and process a '.csv' file with numeric coercion, filtering, and stable indexing\n",
    "    for an exception report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    export_name : str\n",
    "        Base name of the CSV file (without '(Modified).csv').\n",
    "    potential_col : str\n",
    "        Either 'On Potential' or 'Off Potential' (also accepts 'on'/'off', case-insensitive).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (pd.DataFrame, str)\n",
    "        df_out, potential_col\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `potential_col` is not 'on'/'off' or a valid full column name.\n",
    "    \"\"\"\n",
    "    # Map/validate potential inside the function\n",
    "    pot_map = {'on': 'On Potential', 'off': 'Off Potential'}\n",
    "    pot_key = potential_col.strip().lower()\n",
    "    potential_col = pot_map.get(pot_key, potential_col)\n",
    "\n",
    "    # Error handling (Check if a potential column exists)\n",
    "    if potential_col not in {'On Potential', 'Off Potential'}:\n",
    "        raise ValueError(\n",
    "            f\"'potential' must be 'On Potential', 'Off Potential' \"\n",
    "            f\"or shorthand 'on'/'off'; got {potential_col!r}\"\n",
    "        )\n",
    "\n",
    "    file_path = DATA_DIR / f'{export_name}(Modified).csv'\n",
    "    relevant_cols = [\n",
    "        'Station',\n",
    "        'Stationing (ft)',\n",
    "        'Latitude',\n",
    "        'Longitude',\n",
    "        potential_col,\n",
    "        'ACVG Indication (dBV)'\n",
    "    ]\n",
    "\n",
    "    # Read only relevant columns\n",
    "    df_out = pd.read_csv(file_path, usecols=lambda c: c in relevant_cols)\n",
    "\n",
    "    # Drop rows with missing or zero potential\n",
    "    df_out = df_out.loc[df_out[potential_col].notna() & (df_out[potential_col] != 0)].copy()\n",
    "\n",
    "    # Column order\n",
    "    df_out = df_out.reindex(columns=[c for c in relevant_cols if c in df_out.columns])\n",
    "\n",
    "    return df_out, potential_col"
   ],
   "id": "702fb3b1a62e30db",
   "outputs": [],
   "execution_count": 454
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exception Report Crossings",
   "id": "b19cc052807ef68f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.903999Z",
     "start_time": "2025-08-11T21:12:26.899902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exception_report_crossings(\n",
    "        df_in: pd.DataFrame,\n",
    "        *,\n",
    "        potential_col: str,\n",
    "        threshold: float\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Identify and filter threshold crossing events in potential data, removing single-point spikes\n",
    "    and returning both cleaned data and detected outliers.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    1. Flags rows where the `potential` column meets or exceeds the given `threshold`.\n",
    "    2. Calculates transitions between rows:\n",
    "    \n",
    "        - +1 = rising edge (below threshold → above threshold)\n",
    "        - -1 = falling edge (above threshold → below threshold)\n",
    "        - 0  = no change.\n",
    "        \n",
    "    3. Returns: \n",
    "    \n",
    "        - df_out : Cleaned dataframe of threshold crossings without single-point spikes.\n",
    "        - df_outliers : Dataframe of detected outlier spike events.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_in : pd.DataFrame\n",
    "        Input dataframe containing time series data and a `Potential` column.\n",
    "    potential_col : str\n",
    "        Name of the column containing potential values to evaluate.\n",
    "    threshold : float\n",
    "        Threshold value for determining crossings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (pd.DataFrame, pd.DataFrame)\n",
    "        df_out, df_outliers\n",
    "    \"\"\"\n",
    "    # Potential column\n",
    "    potential_col = df_in[potential_col]\n",
    "\n",
    "    # Convert to float\n",
    "    threshold = float(threshold)\n",
    "\n",
    "    # Boolean mask indicating which rows have potential values at or above the threshold\n",
    "    if threshold == Config.POTENTIAL_850:\n",
    "        point = potential_col >= threshold\n",
    "\n",
    "    elif threshold == Config.POTENTIAL_1200:\n",
    "        point = potential_col <= threshold\n",
    "\n",
    "    # Boolean mask of the previous row's threshold state (False for the first row)\n",
    "    point_prev = point.shift(1, fill_value=False)\n",
    "\n",
    "    # Convert boolean masks to integers (True → 1, False → 0) for arithmetic comparison\n",
    "    point_int = point.astype(int)\n",
    "    point_prev_int = point_prev.astype(int)\n",
    "\n",
    "    # +1 = rising ('-.), -1 = falling (.-'), 0 = no change\n",
    "    transition = point_int - point_prev_int\n",
    "\n",
    "    # Replace rows where transition == -1 (falling) with the previous row\n",
    "    df_out = df_in.copy()\n",
    "    mask_fall = (transition == -1)\n",
    "    df_out.loc[mask_fall, :] = df_out.shift(1).loc[mask_fall, :]\n",
    "\n",
    "    # Detect a (1, -1) transition pair, which represents a single-point spike:\n",
    "    #  - start_of_pair: marks the first row of the spike (rising followed falling)\n",
    "    #  - to_drop: marks both the spike's start row (rising) and the immediate next row (falling)\n",
    "    #  - fillna(False): ensures no NaN values in the mask (important at dataframe edges)\n",
    "    start_of_pair = (transition == 1) & (transition.shift(-1) == -1)\n",
    "\n",
    "    # Drop rows\n",
    "    to_drop = start_of_pair | start_of_pair.shift(1)\n",
    "    to_drop = to_drop.fillna(False)\n",
    "\n",
    "    # Keep rows\n",
    "    to_keep = (transition != 0) & (~to_drop)\n",
    "\n",
    "    # Outlier dataframe (drop duplicate stations)\n",
    "    df_outliers = df_out.loc[to_drop].drop_duplicates(subset='Station').reset_index(drop=True)\n",
    "\n",
    "    # Crossings dataframe\n",
    "    df_out = df_out.loc[to_keep].reset_index(drop=True)\n",
    "\n",
    "    # If df_out has an odd number of rows (Deal with last value), append the last row from df_in\n",
    "    if len(df_out) % 2 != 0:\n",
    "        df_out = pd.concat([df_out, df_in.tail(1)], ignore_index=True)\n",
    "\n",
    "    return df_out, df_outliers"
   ],
   "id": "9a9bffde8eb69efc",
   "outputs": [],
   "execution_count": 455
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exception Report To Excel",
   "id": "866f294a993e6922"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.930813Z",
     "start_time": "2025-08-11T21:12:26.923954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exception_report_to_excel(\n",
    "        export_name: str,\n",
    "        df_in: pd.DataFrame,\n",
    "        total_miles: float,\n",
    "        sheet_name: str,\n",
    "        *,\n",
    "        acvg_threshold: float = 45.0,\n",
    "        interval_closed: str = 'both',\n",
    "        acvg_col: str = 'ACVG Indication (dBV)'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pair alternating rows of an exception report into start/end segments and \n",
    "    prepare an Excel-ready DataFrame with segment details and optional ACVG max values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    export_name : str\n",
    "        Part of the name for Excel export file.\n",
    "    df_in : pd.DataFrame\n",
    "        Input DataFrame containing at least the following columns:\n",
    "        \n",
    "        'Station', 'Stationing (ft)', 'Latitude', 'Longitude'. Optionally includes the ACVG column.\n",
    "    total_miles : float\n",
    "        Total number of miles across stations.\n",
    "    sheet_name : str\n",
    "        Sheet name for Excel export file.\n",
    "    acvg_threshold : float, default 45.0\n",
    "        Minimum ACVG value (dBV) to be considered when computing per-segment maximum.\n",
    "    interval_closed : {'both', 'neither', 'left', 'right'}, default 'both'\n",
    "        Whether each segment interval is closed on the left, right, both, or neither \n",
    "        when evaluating ACVG points.\n",
    "    acvg_col : str, default 'ACVG Indication (dBV)'\n",
    "        Name of the ACVG column in the DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        df_out\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # SEGMENT PAIRS\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Pair rows into segments\n",
    "    starts = df_in.iloc[::2].reset_index(drop=True)\n",
    "    ends = df_in.iloc[1::2].reset_index(drop=True)\n",
    "    nseg = len(starts)\n",
    "\n",
    "    # Segment lengths\n",
    "    length = ends['Station'] - starts['Station']\n",
    "\n",
    "    # # Create empty series\n",
    "    # acvg_max = pd.Series(pd.NA, index=range(nseg), dtype='Float64')\n",
    "    # \n",
    "    # # ACVG max >= threshold in [start, end]\n",
    "    # if {'Station', acvg_col} <= set(df_in.columns) and nseg:\n",
    "    #     # ACVG slice of dataframe above threshold\n",
    "    #     df_acvg = df_in[['Station', acvg_col]].copy()\n",
    "    #     df_acvg = df_acvg.loc[df_acvg[acvg_col] >= acvg_threshold]\n",
    "    # \n",
    "    #     if not df_acvg.empty:\n",
    "    #         # Build an IntervalIndex representing each segment's station range\n",
    "    #         intervals = pd.IntervalIndex.from_arrays(\n",
    "    #             starts['Station'],\n",
    "    #             ends['Station'],\n",
    "    #             closed=interval_closed,\n",
    "    #         )\n",
    "    # \n",
    "    #         # For each ACVG measurement, find the index of the segment it falls into\n",
    "    #         seg_idx = intervals.get_indexer(df_acvg['Station'])\n",
    "    # \n",
    "    #         # Add the segment index (_seg) to the ACVG DataFrame\n",
    "    #         df_acvg = df_acvg.assign(_seg=seg_idx).loc[lambda x: x['_seg'] >= 0]\n",
    "    # \n",
    "    #         # Group the ACVG data by segment index and get the maximum ACVG value per segment\n",
    "    #         acvg_max_map = df_acvg.groupby('_seg')[acvg_col].max()\n",
    "    # \n",
    "    #         # Fills max acvg value for the segment\n",
    "    #         acvg_max = (\n",
    "    #             pd.Series(range(nseg))\n",
    "    #             .map(acvg_max_map)\n",
    "    #             .fillna('')  # Replace NaN with empty string\n",
    "    #             .astype('object')  # Store strings and numbers together\n",
    "    #         )\n",
    "\n",
    "    # Build final excel ready frame\n",
    "    data = {\n",
    "        # Start\n",
    "        'Station Number': starts['Stationing (ft)'],\n",
    "        'Latitude': starts['Latitude'],\n",
    "        'Longitude': starts['Longitude'],\n",
    "\n",
    "        # End\n",
    "        'Station Number_end': ends['Stationing (ft)'],\n",
    "        'Latitude_end': ends['Latitude'],\n",
    "        'Longitude_end': ends['Longitude'],\n",
    "\n",
    "        # Derived\n",
    "        'Length (ft)': length,\n",
    "        'Comments': pd.Series('', index=range(nseg), dtype='string'),\n",
    "    }\n",
    "\n",
    "    # # Conditionally add ACVG\n",
    "    # if {'Station', acvg_col} <= set(df_in.columns):\n",
    "    #     data['ACVG Max (dBV)'] = acvg_max\n",
    "\n",
    "    # Build DataFrame\n",
    "    df_out = pd.DataFrame(data)\n",
    "\n",
    "    # Define final column order dynamically\n",
    "    cols = ['Station Number', 'Latitude', 'Longitude', 'Station Number_end', 'Latitude_end',\n",
    "            'Longitude_end', 'Length (ft)', 'Comments']\n",
    "\n",
    "    # if 'ACVG Max (dBV)' in df_out.columns:\n",
    "    #     cols.append('ACVG Max (dBV)')\n",
    "\n",
    "    # Apply column order\n",
    "    df_out = df_out[cols]\n",
    "\n",
    "    # Rename _end columns\n",
    "    df_out = df_out.rename(columns={\n",
    "        'Station Number_end': 'Station Number',\n",
    "        'Latitude_end': 'Latitude',\n",
    "        'Longitude_end': 'Longitude',\n",
    "    })\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # EXCEL EXPORT\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    template_path = EXCEPTION_REPORT_DIR / 'Default.xlsx'\n",
    "    file_path = DATA_DIR / f\"{export_name}(Exception Report).xlsx\"\n",
    "\n",
    "    # Copy the template to the output path\n",
    "    if not file_path.exists():\n",
    "        copyfile(template_path, file_path)\n",
    "\n",
    "    # Open file\n",
    "    wb = load_workbook(file_path)\n",
    "    ws = wb[sheet_name]\n",
    "\n",
    "    # Assign values\n",
    "    ws.cell(1, 1).value = f\"{Config.CLIENT} ({export_name.split(' (SN')[0]})\"\n",
    "    ws.cell(2, 1).value = (\n",
    "        f\"{export_name.split('SN')[1].split()[0]} to \"\n",
    "        f\"{export_name.split('SN')[2].split(')')[0]}\"\n",
    "    )\n",
    "    ws.cell(4, 2).value = round(total_miles * 5280)  # Total feet\n",
    "    ws.cell(5, 2).value = total_miles  # Total miles\n",
    "    ws.cell(4, 5).value = round(df_out['Length (ft)'].sum(), 2)  # Total length\n",
    "    ws.cell(5, 5).value = round(\n",
    "        df_out['Length (ft)'].sum() / total_miles / 5280 * 100, 2\n",
    "    )  # Length %\n",
    "\n",
    "    # Data entry\n",
    "    start_row, start_col = 9, 1\n",
    "    for r_idx, row in enumerate(\n",
    "            dataframe_to_rows(df_out, index=False, header=False), start=start_row\n",
    "    ):\n",
    "        for c_idx, value in enumerate(row, start=start_col):\n",
    "            ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "    # Last data row\n",
    "    last_data_row = start_row + len(df_out) - 1\n",
    "\n",
    "    # Delete everything below it down to row 200 (inclusive)\n",
    "    delete_from = last_data_row + 1\n",
    "    limit = 200\n",
    "    if delete_from <= limit:\n",
    "        ws.delete_rows(delete_from, limit - last_data_row)\n",
    "\n",
    "    # Delete empty worksheet\n",
    "    if df_out.empty:\n",
    "        wb.remove(ws)\n",
    "\n",
    "    # Save workbook\n",
    "    wb.save(file_path)\n",
    "\n",
    "    return df_out"
   ],
   "id": "b92689aeb41fc97",
   "outputs": [],
   "execution_count": 456
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Directories & Paths",
   "id": "df94ac81231e9fbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.972609Z",
     "start_time": "2025-08-11T21:12:26.970354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directories\n",
    "ROOT_DIR = Path.cwd().parent\n",
    "DESKTOP_DIR = Path.home() / 'Desktop'\n",
    "ORIGINAL_DATA_DIR = ROOT_DIR / 'Original Data'\n",
    "EXCEPTION_REPORT_DIR = ROOT_DIR / 'Exception Report Templates'\n",
    "OUTPUT_DIR = DESKTOP_DIR / 'Output'\n",
    "DATA_DIR = OUTPUT_DIR / 'Data'\n",
    "KMZ_DIR = OUTPUT_DIR / 'KMZ'\n",
    "LOGS_DIR = OUTPUT_DIR / 'Logs'"
   ],
   "id": "1c6a6d9c27799d6a",
   "outputs": [],
   "execution_count": 458
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:26.999042Z",
     "start_time": "2025-08-11T21:12:26.994312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Replaces output directory with an empty one\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    shutil.rmtree(OUTPUT_DIR)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR)\n",
    "os.makedirs(DATA_DIR)\n",
    "os.makedirs(KMZ_DIR)\n",
    "os.makedirs(LOGS_DIR)"
   ],
   "id": "56605e5676cf3d20",
   "outputs": [],
   "execution_count": 460
  },
  {
   "cell_type": "markdown",
   "source": "# Data",
   "metadata": {
    "collapsed": false
   },
   "id": "2d50de70870fd6f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Original Data",
   "id": "aa0da93d53ad1eb2"
  },
  {
   "cell_type": "code",
   "source": [
    "# List for files excluding ones starting with '.'\n",
    "original_data_list = [file for file in os.listdir(ORIGINAL_DATA_DIR) if not file.startswith('.')]\n",
    "\n",
    "# Modify name of original data files\n",
    "for idx, file_name in enumerate(original_data_list):\n",
    "    # Original file name\n",
    "    original_name = ORIGINAL_DATA_DIR / file_name\n",
    "\n",
    "    # Modify file name\n",
    "    if '(SN' not in file_name and ').csv' not in file_name:\n",
    "        file_name = file_name.replace(' SN', ' (SN')\n",
    "        file_name = file_name.replace('.csv', ').csv')\n",
    "        file_name = file_name.replace('.CSV', ').csv')\n",
    "        file_name = file_name.replace('.DAT', ').csv')\n",
    "        file_name = file_name.replace('TO (SN', 'TO SN')\n",
    "\n",
    "        # New file name\n",
    "        new_name = ORIGINAL_DATA_DIR / file_name\n",
    "\n",
    "        # Rename files in directory\n",
    "        os.rename(original_name, new_name)\n",
    "\n",
    "        # Raname files in list\n",
    "        original_data_list[idx] = new_name.split('Original Data/')[1]\n",
    "\n",
    "# Sort\n",
    "original_data_list = natsorted(original_data_list)\n",
    "\n",
    "# Export name list\n",
    "export_name_list = natsorted([name.split('.csv')[0] for name in original_data_list])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:27.003943Z",
     "start_time": "2025-08-11T21:12:27.000872Z"
    }
   },
   "id": "f14b0d756d325a17",
   "outputs": [],
   "execution_count": 461
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataframe",
   "id": "ce77610a88e5618b"
  },
  {
   "cell_type": "code",
   "source": [
    "log_dict = {}\n",
    "dfs = {}\n",
    "total_miles_list = []  # List for total miles per '.csv' file\n",
    "total_rows_dropped = []  # List for total rows dropped that don't have GPS coordinates\n",
    "starting_stationing_list = []  # List for starting stationing per '.csv' file\n",
    "i = 0  # Loop counter for station numbers\n",
    "j = 0  # List counter for '.csv' files\n",
    "\n",
    "# Goes through each '.csv' in the folder\n",
    "while j < len(original_data_list):\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # LOG DICTIONARY\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    log_dict[export_name_list[j]] = {\n",
    "        'Dataframe': {\n",
    "            'Rows Dropped': None\n",
    "        },\n",
    "        'Statistics': {\n",
    "            'Mean': None,\n",
    "            'Mode': None,\n",
    "            'Std': None,\n",
    "            'Total Count': None,\n",
    "            'Cutoff Count': None,\n",
    "            'Outliers Count': None,\n",
    "            'Duplicates Count': None\n",
    "        },\n",
    "        'Measurements': {\n",
    "            'On': None,\n",
    "            'Off': None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # DATAFRAME\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Create dataframe\n",
    "    df_cis = pd.read_csv(ORIGINAL_DATA_DIR / original_data_list[j])\n",
    "    df_cis.to_csv(DATA_DIR / f\"{export_name_list[j]}(Original).csv\", index=False)\n",
    "\n",
    "    # Rename columns\n",
    "    rename_columns_dict = {\n",
    "        'records': 'Station',\n",
    "        'milepost': 'Station',\n",
    "        'ps on': 'On Potential',\n",
    "        'structureps': 'On Potential',\n",
    "        'ps off': 'Off Potential',\n",
    "        'structureirf': 'Off Potential',\n",
    "        'comment': 'Comments',\n",
    "        'comments': 'Comments',\n",
    "        'locationdescription': 'Comments',\n",
    "        'latitude': 'Latitude',\n",
    "        'longitude': 'Longitude',\n",
    "        'ACVG Indication (dB_V)': 'ACVG Indication (dBV)'\n",
    "    }\n",
    "\n",
    "    # Replace original names to correct format\n",
    "    df_cis.columns = [rename_columns_dict.get(x.lower(), x) for x in df_cis.columns]\n",
    "\n",
    "    # Columns for dataframe\n",
    "    cols = ['Station', 'On Potential', 'Off Potential', 'Native',\n",
    "            'Comments', 'Latitude', 'Longitude',\n",
    "            'ACVG Indication (dBV)', 'ACVG Notes', 'PCM Data (Amps)', 'PCM % Change']\n",
    "\n",
    "    # Create dataframe from columns that exist\n",
    "    df_cis = df_cis[df_cis.columns.intersection(cols)]\n",
    "\n",
    "    # Reversing rows for flipped SN\n",
    "    if config.REVERSE:\n",
    "        # Reversing rows\n",
    "        df_cis.iloc[:, :] = df_cis.iloc[:, :].values[::-1]\n",
    "\n",
    "        # Reordering\n",
    "        df_cis['Station'] = abs(max(df_cis['Station']) - df_cis['Station'])\n",
    "\n",
    "    # Desired columns\n",
    "    cols = ['On Potential', 'Off Potential', 'Native']\n",
    "\n",
    "    for col in cols:\n",
    "        if col in df_cis.columns:\n",
    "            # Delete rows that CIS was skipped and reset the index\n",
    "            df_cis = df_cis.loc[df_cis[col] != 'SKIP'].reset_index(drop=True)\n",
    "\n",
    "            # Convert object columns to numbers\n",
    "            df_cis[col] = pd.to_numeric(df_cis[col], errors='coerce')\n",
    "\n",
    "            # Replace empty values with 0\n",
    "            df_cis[col] = df_cis[col].replace(np.nan, 0)\n",
    "\n",
    "            # Convert positive values to negative\n",
    "            df_cis[col] = df_cis[col].abs() * (-1)\n",
    "\n",
    "            # Replace exact values\n",
    "            df_cis[col] = df_cis[col].replace(-0.85, -0.850001)\n",
    "            df_cis[col] = df_cis[col].replace(-1.2, -1.20001)\n",
    "\n",
    "        # Divide by 1000 if needed\n",
    "        if col in df_cis.columns and abs(df_cis[col].mean()) > 100:\n",
    "            df_cis[col] /= 1000\n",
    "\n",
    "    # Trim white space from comments\n",
    "    df_cis['Comments'] = df_cis['Comments'].str.strip()\n",
    "\n",
    "    # Create 'Distance (ft)' column\n",
    "    df_cis['Distance (ft)'] = 0.00\n",
    "\n",
    "    # Initial rows \n",
    "    last_index2 = df_cis.last_valid_index()\n",
    "\n",
    "    # Drop rows that don't have GPS coordinates\n",
    "    df_cis['Latitude'] = df_cis['Latitude'].replace('', np.nan)\n",
    "    df_cis.dropna(subset=['Latitude'], inplace=True)\n",
    "    df_cis.reset_index(drop=True, inplace=True)\n",
    "    last_index = df_cis.last_valid_index()\n",
    "    total_rows_dropped.append(last_index2 - last_index)\n",
    "\n",
    "    log_dict[export_name_list[j]]['Dataframe']['Rows Dropped'] = total_rows_dropped[j]\n",
    "\n",
    "    # Records total miles in a list\n",
    "    total_miles_list.append(max(df_cis['Station']) / 5280)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # ACVG, PCM & PCM %\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    if 'ACVG Indication (dBV)' in df_cis.columns:\n",
    "        # Convert object columns to numbers\n",
    "        df_cis['ACVG Indication (dBV)'] = pd.to_numeric(\n",
    "            df_cis['ACVG Indication (dBV)'], errors='coerce'\n",
    "        )\n",
    "\n",
    "        # Replace empty values with 0\n",
    "        df_cis['ACVG Indication (dBV)'] = df_cis['ACVG Indication (dBV)'].replace(np.nan, 0)\n",
    "\n",
    "        # Trim white space from comments\n",
    "        df_cis['ACVG Notes'] = df_cis['ACVG Notes'].str.strip()\n",
    "\n",
    "    if 'PCM Data (Amps)' in df_cis.columns:\n",
    "        # Convert object columns to numbers\n",
    "        df_cis['PCM Data (Amps)'] = pd.to_numeric(df_cis['PCM Data (Amps)'], errors='coerce')\n",
    "\n",
    "        # Replace empty values with 0\n",
    "        df_cis['PCM Data (Amps)'] = df_cis['PCM Data (Amps)'].replace(np.nan, 0)\n",
    "\n",
    "    if 'PCM % Change' in df_cis.columns:\n",
    "        # Convert object columns to numbers\n",
    "        df_cis['PCM % Change'] = pd.to_numeric(df_cis['PCM % Change'], errors='coerce')\n",
    "\n",
    "        # Replace empty values with 0\n",
    "        df_cis['PCM % Change'] = df_cis['PCM % Change'].replace(np.nan, 0)\n",
    "\n",
    "        # Absolute value\n",
    "        df_cis['PCM % Change'] = abs(df_cis['PCM % Change'])\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # STATION NUMBERS\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Extract starting station number from '.csv' title\n",
    "    starting_stationing_list.append(\n",
    "        float(original_data_list[j].split('SN')[1].split()[0].replace('+', ''))\n",
    "    )\n",
    "\n",
    "    # Add 'Stationing (ft)' column to hold calculated stationing values\n",
    "    df_cis['Stationing (ft)'] = ''\n",
    "\n",
    "    # Infers actual station number (XX+XX)\n",
    "    while i <= last_index:\n",
    "        current_station = df_cis.at[i, 'Station']\n",
    "        stationing_ft = str(starting_stationing_list[j] + current_station).split('.')[0]\n",
    "        string_length = len(stationing_ft)\n",
    "\n",
    "        if -100 < (starting_stationing_list[j] + current_station) < 0:\n",
    "            station_value = stationing_ft.replace('-', '')\n",
    "            df_cis.at[i, 'Stationing (ft)'] = (\n",
    "                f\" -0{station_value[:string_length - 2]}+{station_value[string_length - 2:]}\"\n",
    "            )\n",
    "\n",
    "        elif 0 <= (starting_stationing_list[j] + current_station) < 100:\n",
    "            df_cis.at[i, 'Stationing (ft)'] = (\n",
    "                f\" 0{stationing_ft[:string_length - 2]}+{stationing_ft[string_length - 2:]}\"\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            df_cis.at[i, 'Stationing (ft)'] = (\n",
    "                f\"{stationing_ft[:string_length - 2]}+{stationing_ft[string_length - 2:]}\"\n",
    "            )\n",
    "\n",
    "        # Last row exception\n",
    "        if i != last_index:\n",
    "            # Calculates distance between GPS coordinates and stationing (ft)\n",
    "            try:\n",
    "                df_cis.at[i + 1, 'Distance (ft)'] = geodesic(\n",
    "                    [df_cis.at[i, 'Latitude'], df_cis.at[i, 'Longitude']],\n",
    "                    [df_cis.at[i + 1, 'Latitude'], df_cis.at[i + 1, 'Longitude']]\n",
    "                ).ft\n",
    "\n",
    "            except ZeroDivisionError:\n",
    "                df_cis.at[i + 1, 'Distance (ft)'] = 0\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # STATISTICS # TODO: Go through statistics to see what is valuable\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    df_cis_stats = df_cis.copy()\n",
    "    df_cis_stats = df_cis_stats[(config.LOWER_CUTOFF < df_cis_stats['Station'].diff().abs())\n",
    "                                & (df_cis_stats['Station'].diff().abs() <= config.UPPER_CUTOFF)]\n",
    "\n",
    "    # Mean\n",
    "    log_dict[export_name_list[j]]['Statistics']['Mean'] = (\n",
    "        df_cis_stats['Distance (ft)'][1:].mean()\n",
    "    )\n",
    "\n",
    "    # Mode\n",
    "    log_dict[export_name_list[j]]['Statistics']['Mode'] = (\n",
    "        df_cis_stats['Distance (ft)'].round(1).mode()[0]\n",
    "    )\n",
    "\n",
    "    # Standard deviation\n",
    "    log_dict[export_name_list[j]]['Statistics']['Std'] = (\n",
    "        df_cis_stats['Distance (ft)'][1:].std()\n",
    "    )\n",
    "\n",
    "    # Z-score (Identify outliers)\n",
    "    z_scores = np.abs(stats.zscore(df_cis_stats['Distance (ft)']))\n",
    "    df_cis_stats['z_scores'] = z_scores\n",
    "    df_outliers = (\n",
    "        df_cis_stats[df_cis_stats['z_scores'] > 2.576][['Stationing (ft)', 'Distance (ft)']]\n",
    "    )\n",
    "\n",
    "    # Total count of data within the distance cutoff\n",
    "    log_dict[export_name_list[j]]['Statistics']['Total Count'] = (\n",
    "        df_cis_stats['Distance (ft)'].round(1).count()\n",
    "    )\n",
    "\n",
    "    # Count of data that fall outside the cutoff\n",
    "    log_dict[export_name_list[j]]['Statistics']['Cutoff Count'] = (\n",
    "        df_cis_stats[(config.LOWER_CUTOFF < df_cis_stats['Distance (ft)']) &\n",
    "                     (df_cis_stats['Distance (ft)'] <=\n",
    "                      config.UPPER_CUTOFF)]['Distance (ft)'].count())\n",
    "\n",
    "    # Count of data that are outliers\n",
    "    log_dict[export_name_list[j]]['Statistics']['Outliers Count'] = (\n",
    "        df_outliers['Distance (ft)'].count()\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # EXPORTS\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Export modified data to csv\n",
    "    df_cis.to_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\", index=False)\n",
    "\n",
    "    # Export outlier data to csv\n",
    "    df_outliers.to_csv(DATA_DIR / f\"{export_name_list[j]}(GPS Outliers).csv\", index=False)\n",
    "\n",
    "    # Counters\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:34.020269Z",
     "start_time": "2025-08-11T21:12:27.023444Z"
    }
   },
   "id": "ca8cc75b0f341d29",
   "outputs": [],
   "execution_count": 462
  },
  {
   "cell_type": "markdown",
   "source": "# Google Earth",
   "metadata": {
    "collapsed": false
   },
   "id": "90d0bb4d93df8728"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Folder Structure",
   "id": "8cf63edf3c2bc346"
  },
  {
   "cell_type": "code",
   "source": [
    "kmz_path_list = []  # List for kmz paths\n",
    "cis_kmz = []  # List for '.kmz' files\n",
    "type_folders = []  # List for folders\n",
    "total_folders = 9\n",
    "current_mile = 1\n",
    "k = 0  # List counter for folders\n",
    "j = 0  # List counter for '.csv' files\n",
    "i = 0  # List counter for '.kmz' files based on miles\n",
    "\n",
    "# Create '.kmz' files per mile #\n",
    "while j < len(total_miles_list):\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create folders\n",
    "    while miles_remaining > 0:\n",
    "        # Separate folders by mile\n",
    "        cis_kmz.append(f\"{export_name_list[j]} (Mile {current_mile})\")\n",
    "        cis_kmz[i] = simplekml.Kml()\n",
    "\n",
    "        # Create list placeholders for folders\n",
    "        for l in range(total_folders):\n",
    "            type_folders.append('')\n",
    "\n",
    "        type_folders[k + 0] = cis_kmz[i].newfolder(name='On')\n",
    "        type_folders[k + 1] = cis_kmz[i].newfolder(name='Off')\n",
    "\n",
    "        if 'Native' in df_cis.columns:\n",
    "            type_folders[k + 2] = cis_kmz[i].newfolder(name='Native')\n",
    "\n",
    "        type_folders[k + 3] = cis_kmz[i].newfolder(name='Comments')\n",
    "        type_folders[k + 4] = cis_kmz[i].newfolder(name='-1.2 V')\n",
    "        type_folders[k + 5] = cis_kmz[i].newfolder(name='-0.85 V')\n",
    "\n",
    "        if 'ACVG Indication (dBV)' in df_cis.columns:\n",
    "            type_folders[k + 6] = cis_kmz[i].newfolder(name='ACVG Indication')\n",
    "\n",
    "        if 'PCM Data (Amps)' in df_cis.columns:\n",
    "            type_folders[k + 7] = cis_kmz[i].newfolder(name='PCM (Amps)')\n",
    "\n",
    "        if 'PCM % Change' in df_cis.columns:\n",
    "            type_folders[k + 8] = cis_kmz[i].newfolder(name='PCM (%)')\n",
    "\n",
    "        # Directory name\n",
    "        kmz_path_list.append(KMZ_DIR / export_name_list[j])\n",
    "\n",
    "        # Create directories for each file  \n",
    "        if not os.path.exists(kmz_path_list[i]):\n",
    "            os.makedirs(kmz_path_list[i])\n",
    "\n",
    "        # Transform directories to paths for easier access\n",
    "        kmz_name = f\"{export_name_list[j]} (Mile {current_mile}).kmz\"\n",
    "        kmz_path_list[i] = kmz_path_list[i] / kmz_name\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        i += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    j += 1\n",
    "    current_mile = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:34.027849Z",
     "start_time": "2025-08-11T21:12:34.021391Z"
    }
   },
   "id": "484295ba24e627d6",
   "outputs": [],
   "execution_count": 463
  },
  {
   "cell_type": "markdown",
   "source": [
    "## On"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19940d4e9c4dc1d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:37.487818Z",
     "start_time": "2025-08-11T21:12:34.028529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feet_counter = 5280\n",
    "style = simplekml.Style()\n",
    "i = 0  # Loop counter for rows\n",
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 0  # Loop counter for type folders (0 = 'On')\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and 'On Potential' in df_cis.columns and config.PLOT_3D:\n",
    "    df_cis_on = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    df_cis_on = df_cis_on[df_cis_on['On Potential'] != 0]\n",
    "    df_cis_on = (\n",
    "        df_cis_on[['Station', 'Stationing (ft)', 'Comments', 'Latitude',\n",
    "                   'Longitude', 'On Potential']].reset_index(drop=True)\n",
    "    )\n",
    "    df_cis_on['On Potential'] = df_cis_on['On Potential'] * (-1)\n",
    "    last_index = df_cis_on.last_valid_index()\n",
    "    log_dict[export_name_list[j]]['Measurements']['On'] = last_index + 1\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_on.at[i, 'Station'] < feet_counter:\n",
    "            # Break loop if there are no 'On' potentials\n",
    "            if df_cis_on.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(\n",
    "                name=df_cis_on.at[i, 'On Potential'] * (-1),\n",
    "                visibility=config.DATA_VISIBILITY\n",
    "            )\n",
    "            pnt.style.balloonstyle.text = (\n",
    "                f\"Potential (On): -{df_cis_on.at[i, 'On Potential']} V\\n\"\n",
    "                f\"Longitude: {df_cis_on.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_on.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_on.at[i, 'Stationing (ft)']}\"\n",
    "            )\n",
    "            pnt.coords = [\n",
    "                (df_cis_on.at[i, 'Longitude'], df_cis_on.at[i, 'Latitude'],\n",
    "                 df_cis_on.at[i, 'On Potential'] * config.SCALE_FACTOR)\n",
    "            ]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_ON\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 0\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Export duplicate GPS coordinates to csv\n",
    "    if config.PLOT_3D:\n",
    "        df_duplicates = df_cis_on[df_cis_on.duplicated(\n",
    "            subset=['Latitude', 'Longitude'],\n",
    "            keep=False\n",
    "        )]\n",
    "        df_duplicates.to_csv(DATA_DIR / f\"{export_name_list[j]}(Duplicate GPS).csv\", index=False)\n",
    "        log_dict[export_name_list[j]]['Statistics']['Duplicates Count'] = (\n",
    "            df_duplicates['Station'].value_counts().sum()\n",
    "        )\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "id": "628689230ebcac0c",
   "outputs": [],
   "execution_count": 464
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Off"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8ab0b3f4442f8e7"
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 1  # Loop counter for type folders (1 = 'Off')\n",
    "kmz_file = 0\n",
    "off_measurements = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and 'Off Potential' in df_cis.columns and config.PLOT_3D:\n",
    "    df_cis_off = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    df_cis_off = df_cis_off[df_cis_off['Off Potential'] != 0]\n",
    "    df_cis_off = df_cis_off[['Station', 'Stationing (ft)', 'Latitude', 'Longitude',\n",
    "                             'Off Potential']].reset_index(drop=True)\n",
    "    df_cis_off['Off Potential'] = df_cis_off['Off Potential'] * (-1)\n",
    "    last_index = df_cis_off.last_valid_index()\n",
    "    log_dict[export_name_list[j]]['Measurements']['Off'] = last_index + 1\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_off.at[i, 'Station'] < feet_counter:\n",
    "            # Break loop if there are no 'Off' potentials\n",
    "            if df_cis_off.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_off.at[i, 'Off Potential'] * (-1),\n",
    "                                           visibility=config.DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = (\n",
    "                f\"Potential (Off): -{df_cis_off.at[i, 'Off Potential']} V\\n\"\n",
    "                f\"Longitude: {df_cis_off.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_off.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_off.at[i, 'Stationing (ft)']}\")\n",
    "            pnt.coords = [(df_cis_off.at[i, 'Longitude'], df_cis_off.at[i, 'Latitude'],\n",
    "                           df_cis_off.at[i, 'Off Potential'] * config.SCALE_FACTOR)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_OFF\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE\n",
    "            pnt.style.linestyle.width = 0.01\n",
    "            pnt.style.linestyle.color = simplekml.Color.rgb(255, 255, 255, round(255 * 0.15))\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 1\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:38.672240Z",
     "start_time": "2025-08-11T21:12:37.489189Z"
    }
   },
   "id": "1156516e922065ef",
   "outputs": [],
   "execution_count": 465
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Native",
   "id": "da7136d675f79c86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:38.677403Z",
     "start_time": "2025-08-11T21:12:38.673076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 2  # Loop counter for type folders (2 = 'Native')\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and 'Native' in df_cis.columns and config.PLOT_3D:\n",
    "    df_cis_native = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    df_cis_native = df_cis_native[df_cis_native['Native'] != 0]\n",
    "    df_cis_native = df_cis_native[['Station', 'Stationing (ft)', 'Latitude', 'Longitude',\n",
    "                                   'Native']].reset_index(drop=True)\n",
    "    df_cis_native['Native'] = df_cis_native['Native'] * (-1)\n",
    "    last_index = df_cis_native.last_valid_index()\n",
    "    off_measurements = last_index + 1\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_native.at[i, 'Station'] < feet_counter:\n",
    "            # Break loop if there are no 'Native' potentials\n",
    "            if df_cis_native.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_native.at[i, 'Native'] * (-1),\n",
    "                                           visibility=config.DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = (\n",
    "                f\"Potential (Native): -{df_cis_native.at[i, 'Native']} V\\n\"\n",
    "                f\"Longitude: {df_cis_native.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_native.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_native.at[i, 'Stationing (ft)']}\")\n",
    "            pnt.coords = [(df_cis_native.at[i, 'Longitude'], df_cis_native.at[i, 'Latitude'],\n",
    "                           df_cis_native.at[i, 'Native'] * config.SCALE_FACTOR)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_NATIVE\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 0\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "id": "ace636848f9dce50",
   "outputs": [],
   "execution_count": 466
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "818a6aadca1f7a72"
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 3  # Loop counter for type folders (3 = 'Comments')\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and 'Comments' in df_cis.columns and config.PLOT_3D:\n",
    "    df_cis_comments = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    df_cis_comments.dropna(subset=['Comments'], inplace=True)\n",
    "    df_cis_comments.reset_index(drop=True, inplace=True)\n",
    "    last_index = df_cis_comments.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_comments.at[i, 'Station'] < feet_counter:\n",
    "            # Break loop if there are no comments\n",
    "            if df_cis_comments.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_comments.at[i, 'Comments'],\n",
    "                                           visibility=config.DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = ''\n",
    "\n",
    "            if 'On Potential' in df_cis.columns:\n",
    "                potential_on = df_cis_comments.at[i, 'On Potential'].__str__() + ' V'\n",
    "                pnt.style.balloonstyle.text += f\"Potential (On): {potential_on}\\n\"\n",
    "\n",
    "            if 'Off Potential' in df_cis.columns:\n",
    "                potential_off = df_cis_comments.at[i, 'Off Potential'].__str__() + ' V'\n",
    "                pnt.style.balloonstyle.text += f\"Potential (Off): {potential_off}\\n\"\n",
    "\n",
    "            if 'Native' in df_cis.columns:\n",
    "                potential_native = df_cis_comments.at[i, 'Native'].__str__() + ' V'\n",
    "                pnt.style.balloonstyle.text += f\"Potential (Native): {potential_native}\\n\"\n",
    "\n",
    "            pnt.style.balloonstyle.text += (\n",
    "                f\"Longitude: {df_cis_comments.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_comments.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_comments.at[i, 'Stationing (ft)']}\\n\"\n",
    "                f\"Comment: {df_cis_comments.at[i, 'Comments']}\")\n",
    "\n",
    "            pnt.coords = [(df_cis_comments.at[i, 'Longitude'],\n",
    "                           df_cis_comments.at[i, 'Latitude'], 0)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_COMMENTS\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE * 1.5\n",
    "            pnt.style.labelstyle.scale = 0.5\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:38.761274Z",
     "start_time": "2025-08-11T21:12:38.678117Z"
    }
   },
   "id": "abdf3743777de556",
   "outputs": [],
   "execution_count": 467
  },
  {
   "cell_type": "markdown",
   "source": [
    "## -1.2 V"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a1751bc186d5651"
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 4  # Loop counter for type folders (4 = '-1.2 V')\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and config.PLOT_3D:\n",
    "    df_cis_1200 = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    last_index = df_cis_1200.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_1200.at[i, 'Station'] < feet_counter:\n",
    "            pnt = type_folders[k].newpoint(name='-1.200', visibility=config.DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = 'Potential: -1.2 V'\n",
    "            pnt.coords = [(df_cis_1200.at[i, 'Longitude'], df_cis_1200.at[i, 'Latitude'],\n",
    "                           1.2 * config.SCALE_FACTOR)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_1200\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 0\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:41.433579Z",
     "start_time": "2025-08-11T21:12:38.762052Z"
    }
   },
   "id": "5cde780ff8eff497",
   "outputs": [],
   "execution_count": 468
  },
  {
   "cell_type": "markdown",
   "source": [
    "## -0.85 V"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58de2af4e8e215a3"
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 5  # Loop counter for type folders (5 = '-0.85 V')\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and config.PLOT_3D:\n",
    "    df_cis_850 = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    last_index = df_cis_850.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_850.at[i, 'Station'] < feet_counter:\n",
    "            pnt = type_folders[k].newpoint(name='-0.850', visibility=config.DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = 'Potential: -0.85 V'\n",
    "            pnt.coords = [(df_cis_850.at[i, 'Longitude'], df_cis_850.at[i, 'Latitude'],\n",
    "                           0.85 * config.SCALE_FACTOR)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_850\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "            pnt.extrude = 0\n",
    "            pnt.style.linestyle.width = 0.01\n",
    "            pnt.style.linestyle.color = simplekml.Color.rgb(255, 255, 255, round(255 * 0.15))\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:43.929932Z",
     "start_time": "2025-08-11T21:12:41.434264Z"
    }
   },
   "id": "7898ce1607c10d0b",
   "outputs": [],
   "execution_count": 469
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ACVG",
   "id": "b3ffc53c1f6b5a0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:43.935443Z",
     "start_time": "2025-08-11T21:12:43.930764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 6  # Loop counter for type folders (6 = \"ACVG Indication (dBV)\")\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and 'ACVG Indication (dBV)' in df_cis.columns and config.PLOT_3D:\n",
    "    df_cis_acvg = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    df_cis_acvg = df_cis_acvg[df_cis_acvg['ACVG Indication (dBV)'] != 0]\n",
    "    df_cis_acvg = df_cis_acvg[['Station', 'Stationing (ft)', 'Latitude', 'Longitude',\n",
    "                               'On Potential', 'Off Potential',\n",
    "                               'ACVG Indication (dBV)', 'ACVG Notes']].reset_index(drop=True)\n",
    "    last_index = df_cis_acvg.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_acvg.at[i, 'Station'] < feet_counter:\n",
    "            # Break loop if there are no ACVG values\n",
    "            if df_cis_acvg.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_acvg.at[i, 'ACVG Indication (dBV)'],\n",
    "                                           visibility=config.DATA_VISIBILITY)\n",
    "\n",
    "            if pd.isnull(df_cis_acvg.at[i, 'ACVG Notes']):\n",
    "                pnt.style.balloonstyle.text = (\n",
    "                    f\"ACVG Indication: {df_cis_acvg.at[i, 'ACVG Indication (dBV)']} dBV\\n\"\n",
    "                    f\"ID: {df_cis_acvg.index[i] + 1}\\n\"\n",
    "                    f\"Longitude: {df_cis_acvg.at[i, 'Longitude']}\\n\"\n",
    "                    f\"Latitude: {df_cis_acvg.at[i, 'Latitude']}\\n\"\n",
    "                    f\"Station (ft): {df_cis_acvg.at[i, 'Stationing (ft)']}\")\n",
    "\n",
    "            else:\n",
    "                pnt.style.balloonstyle.text = (\n",
    "                    f\"ACVG Indication: {df_cis_acvg.at[i, 'ACVG Indication (dBV)']} dBV\\n\"\n",
    "                    f\"ID: {df_cis_acvg.index[i] + 1}\\n\"\n",
    "                    f\"Longitude: {df_cis_acvg.at[i, 'Longitude']}\\n\"\n",
    "                    f\"Latitude: {df_cis_acvg.at[i, 'Latitude']}\\n\"\n",
    "                    f\"Station (ft): {df_cis_acvg.at[i, 'Stationing (ft)']}\\n\"\n",
    "                    f\"Comment: {df_cis_acvg.at[i, 'ACVG Notes']}\")\n",
    "\n",
    "            pnt.coords = [(df_cis_acvg.at[i, 'Longitude'], df_cis_acvg.at[i, 'Latitude'],\n",
    "                           df_cis_acvg.at[i, 'ACVG Indication (dBV)'])]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_ACVG\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE + 0.5\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "id": "4ed772af7638b85a",
   "outputs": [],
   "execution_count": 470
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PCM (Amps)",
   "id": "edf4dcefe0f0e6d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:43.941298Z",
     "start_time": "2025-08-11T21:12:43.937366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 7  # Loop counter for type folders (7 = 'PCM Data (Amps)')\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and 'PCM Data (Amps)' in df_cis.columns and config.PLOT_3D:\n",
    "    df_cis_pcm_amps = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    df_cis_pcm_amps = df_cis_pcm_amps[df_cis_pcm_amps['PCM Data (Amps)'] != 0]\n",
    "    df_cis_pcm_amps = df_cis_pcm_amps[['Station', 'Stationing (ft)', 'Latitude', 'Longitude',\n",
    "                                       'PCM Data (Amps)']].reset_index(drop=True)\n",
    "    last_index = df_cis_pcm_amps.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_pcm_amps.at[i, 'Station'] < feet_counter:\n",
    "            # Break loop if there are no PCM (Amps) values\n",
    "            if df_cis_pcm_amps.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_pcm_amps.at[i, 'PCM Data (Amps)'],\n",
    "                                           visibility=config.DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = (\n",
    "                f\"PCM: {df_cis_pcm_amps.at[i, 'PCM Data (Amps)']} Amps\\n\"\n",
    "                f\"Longitude: {df_cis_pcm_amps.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_pcm_amps.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_pcm_amps.at[i, 'Stationing (ft)']}\")\n",
    "            pnt.coords = [(df_cis_pcm_amps.at[i, 'Longitude'], df_cis_pcm_amps.at[i, 'Latitude'],\n",
    "                           df_cis_pcm_amps.at[i, 'PCM Data (Amps)'] * config.SCALE_PCM)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_PCM\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE + 0.5\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "id": "8b55bd64a095b6cd",
   "outputs": [],
   "execution_count": 471
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PCM (%)",
   "id": "b18db3e305eef57f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:12:43.945861Z",
     "start_time": "2025-08-11T21:12:43.941966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "k = 8  # Loop counter for type folders (8 = 'PCM % Change')\n",
    "kmz_file = 0\n",
    "\n",
    "# Goes through all '.csv' files\n",
    "while j < len(original_data_list) and 'PCM % Change' in df_cis.columns and config.PLOT_3D:\n",
    "    df_cis_pcm_percent = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "    df_cis_pcm_percent = df_cis_pcm_percent[df_cis_pcm_percent['PCM % Change'] != 0]\n",
    "    df_cis_pcm_percent = df_cis_pcm_percent[['Station', 'Stationing (ft)', 'Latitude', 'Longitude',\n",
    "                                             'PCM % Change']].reset_index(drop=True)\n",
    "    last_index = df_cis_pcm_percent.last_valid_index()\n",
    "    miles_remaining = round(total_miles_list[j], 2)\n",
    "\n",
    "    # Create '.kmz' files for each mile #\n",
    "    while miles_remaining > 0:\n",
    "        # Create 3D data points\n",
    "        while i <= last_index and df_cis_pcm_percent.at[i, 'Station'] < feet_counter:\n",
    "            # Break loop if there are no PCM (%) values\n",
    "            if df_cis_pcm_percent.shape[0] == 0:\n",
    "                break\n",
    "\n",
    "            pnt = type_folders[k].newpoint(name=df_cis_pcm_percent.at[i, 'PCM % Change'],\n",
    "                                           visibility=config.DATA_VISIBILITY)\n",
    "            pnt.style.balloonstyle.text = (\n",
    "                f\"PCM: {df_cis_pcm_percent.at[i, 'PCM % Change']} %\\n\"\n",
    "                f\"Longitude: {df_cis_pcm_percent.at[i, 'Longitude']}\\n\"\n",
    "                f\"Latitude: {df_cis_pcm_percent.at[i, 'Latitude']}\\n\"\n",
    "                f\"Station (ft): {df_cis_pcm_percent.at[i, 'Stationing (ft)']}\")\n",
    "            pnt.coords = [(df_cis_pcm_percent.at[i, 'Longitude'],\n",
    "                           df_cis_pcm_percent.at[i, 'Latitude'],\n",
    "                           config.SCALE_PCM_PERCENT +\n",
    "                           df_cis_pcm_percent.at[i, 'PCM % Change'] * 0.5)]\n",
    "            pnt.altitudemode = simplekml.AltitudeMode.relativetoground\n",
    "            pnt.style.iconstyle.icon.href = config.ICON_PCM_PERCENT\n",
    "            pnt.style.iconstyle.scale = config.ICON_SCALE + 0.5\n",
    "            pnt.style.labelstyle.scale = 0\n",
    "\n",
    "            # Counters\n",
    "            i += 1\n",
    "\n",
    "        # Counters\n",
    "        current_mile += 1\n",
    "        miles_remaining -= 1\n",
    "\n",
    "        if 0 < miles_remaining < 1:\n",
    "            current_mile = round(total_miles_list[j], 2)\n",
    "\n",
    "        feet_counter += 5280\n",
    "        kmz_file += 1\n",
    "        k += total_folders\n",
    "\n",
    "    # Counters\n",
    "    feet_counter = 5280\n",
    "    current_mile = 1\n",
    "    i = 0\n",
    "    j += 1"
   ],
   "id": "ae4149442513f61c",
   "outputs": [],
   "execution_count": 472
  },
  {
   "cell_type": "markdown",
   "source": "## KMZs",
   "metadata": {
    "collapsed": false
   },
   "id": "29f0433ee3d1e227"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parallel processing",
   "id": "defe3f372d2e3258"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:06.734104Z",
     "start_time": "2025-08-11T21:12:43.946435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Parallel final save on macOS (fork), sequential fallback otherwise ---\n",
    "import os, multiprocessing as mp\n",
    "\n",
    "\n",
    "def _save_idx(idx):\n",
    "    # child process work; reads cis_kmz/kmz_path_list via copy-on-write memory\n",
    "    # (safe because we use 'fork')\n",
    "    # If you didn't already create the directories earlier, ensure they exist:\n",
    "    os.makedirs(os.path.dirname(kmz_path_list[idx]), exist_ok=True)\n",
    "    cis_kmz[idx].savekmz(kmz_path_list[idx])\n",
    "    return idx\n",
    "\n",
    "\n",
    "# Try to ensure we use 'fork' so we don't need to pickle cis_kmz\n",
    "try:\n",
    "    mp.set_start_method(\"fork\")\n",
    "except RuntimeError:\n",
    "    # start method already set; that's fine\n",
    "    pass\n",
    "\n",
    "ctx = mp.get_context(\"fork\") if \"fork\" in mp.get_all_start_methods() else mp.get_context()\n",
    "workers = min(8, (os.cpu_count() or 4))\n",
    "\n",
    "try:\n",
    "    with ctx.Pool(processes=workers) as pool:\n",
    "        # chunksize tunes task batching; 8–32 is usually good\n",
    "        for _ in pool.imap_unordered(_save_idx, range(len(cis_kmz)), chunksize=16):\n",
    "            pass\n",
    "except Exception as e:\n",
    "    # Fallback: sequential if something blocks forking in your env\n",
    "    print(f\"Parallel save failed ({e}); falling back to sequential…\")\n",
    "    for idx, kml in enumerate(cis_kmz):\n",
    "        os.makedirs(os.path.dirname(kmz_path_list[idx]), exist_ok=True)\n",
    "        kml.savekmz(kmz_path_list[idx])"
   ],
   "id": "d970012800f2f7bf",
   "outputs": [],
   "execution_count": 473
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Rename",
   "id": "26dad00750618896"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:06.737441Z",
     "start_time": "2025-08-11T21:13:06.735234Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO: Add seperation ---",
   "id": "d6adb9c5b05fcce8",
   "outputs": [],
   "execution_count": 474
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "kmz_file = 0\n",
    "all_name_list = []\n",
    "all_kmz_list = []\n",
    "\n",
    "while j < len(total_miles_list):\n",
    "    # List of SNXXXX+XX ranges\n",
    "    sn_list = [''] * (math.ceil(total_miles_list[j]) * 2)\n",
    "\n",
    "    # Last index\n",
    "    last_index_sn = len(sn_list) - 1\n",
    "\n",
    "    # List of '.kmz' file names\n",
    "    name_list = [''] * (math.ceil(total_miles_list[j]))\n",
    "\n",
    "    # List of stations as a nummber\n",
    "    station_list = np.arange(0, math.ceil(total_miles_list[j]) + 1)\n",
    "\n",
    "    # Last index\n",
    "    last_index_station = len(station_list) - 1\n",
    "\n",
    "    # First SN (number)\n",
    "    station_list[0] = starting_stationing_list[j]\n",
    "\n",
    "    # Assign a value of mile (ft) per element\n",
    "    for i in range(1, last_index_station + 1):\n",
    "        station_list[i] = station_list[i - 1] + 5280\n",
    "\n",
    "    # Last SN (number)\n",
    "    station_list[last_index_station] = (\n",
    "        math.ceil(((total_miles_list[j] - math.floor(total_miles_list[j])) * 5280\n",
    "                   + station_list[last_index_station - 1]))\n",
    "    )\n",
    "\n",
    "    #\n",
    "    df_cis = pd.read_csv(DATA_DIR / f\"{export_name_list[j]}(Modified).csv\")\n",
    "\n",
    "    # First SN\n",
    "    closest_index = (\n",
    "        (df_cis['Station'] + starting_stationing_list[j] - station_list[0]).abs().argmin()\n",
    "    )\n",
    "\n",
    "    sn_list[0] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index]}\".replace(' ', '')\n",
    "\n",
    "    s = 1  # station_list counter\n",
    "    i = 1  # sn_list counter\n",
    "\n",
    "    # In between SN\n",
    "    while i < last_index_sn:\n",
    "        closest_index = (\n",
    "            (df_cis['Station'] + starting_stationing_list[j] - station_list[s]).abs().argmin()\n",
    "        )\n",
    "\n",
    "        if df_cis['Station'].loc[closest_index] - station_list[s] >= 0:\n",
    "            # Below closest index\n",
    "            sn_list[i] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index - 1]}\".replace(' ', '')\n",
    "            sn_list[i + 1] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index]}\".replace(' ', '')\n",
    "\n",
    "        else:\n",
    "            # Above closest index\n",
    "            sn_list[i] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index]}\".replace(' ', '')\n",
    "            sn_list[i + 1] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index + 1]}\".replace(' ',\n",
    "                                                                                             '')\n",
    "        # Counters\n",
    "        s += 1\n",
    "        i += 2\n",
    "\n",
    "    # Last SN\n",
    "    closest_index = (\n",
    "            df_cis['Station'] + starting_stationing_list[j] -\n",
    "            station_list[last_index_station]\n",
    "    ).abs().argmin()\n",
    "    sn_list[last_index_sn] = f\"SN{df_cis['Stationing (ft)'].loc[closest_index]}\".replace(' ', '')\n",
    "\n",
    "    # XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "    # Remove duplicate SNs\n",
    "    sn_list = list(OrderedDict.fromkeys(sn_list))\n",
    "\n",
    "    # Get new index\n",
    "    last_index_sn = len(sn_list) - 1\n",
    "\n",
    "    # Get kmz paths\n",
    "    kmz_dir = KMZ_DIR / export_name_list[j]\n",
    "    kmz_files = list(kmz_dir.glob(\"*.kmz\"))\n",
    "\n",
    "    # Sort kmz files\n",
    "    kmz_files = [p.name for p in kmz_files]\n",
    "    kmz_files = natsorted(kmz_files)\n",
    "\n",
    "    s = 0  # sn_list counter\n",
    "\n",
    "    # Name station number ranges\n",
    "    for i in range(0, last_index_station):\n",
    "        name_list[i] = (\n",
    "            f\"{original_data_list[j].split('SN')[0][:-1]}\"\n",
    "            f\"({sn_list[s]} TO {sn_list[s + 1]}).kmz\"\n",
    "        )\n",
    "\n",
    "        # Counter\n",
    "        s += 2\n",
    "\n",
    "    all_name_list.extend(name_list)\n",
    "    all_kmz_list.extend(kmz_files)\n",
    "\n",
    "    # Counter\n",
    "    j += 1\n",
    "\n",
    "# Rename kmz files\n",
    "for i in range(0, len(kmz_path_list)):\n",
    "    src = str(kmz_path_list[i])\n",
    "    dst = src.replace(all_kmz_list[i], all_name_list[i])\n",
    "    os.rename(src, dst)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:06.789241Z",
     "start_time": "2025-08-11T21:13:06.738279Z"
    }
   },
   "id": "f0230805d7c09f0",
   "outputs": [],
   "execution_count": 475
  },
  {
   "cell_type": "markdown",
   "source": "# Exception Report",
   "metadata": {
    "collapsed": false
   },
   "id": "dddd93b34554179"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:06.791670Z",
     "start_time": "2025-08-11T21:13:06.790120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: Add to exception report when Off is more negative than On\n",
    "# TODO: Add to exception report where skips exist\n",
    "# TODO: Add to exception report between TS "
   ],
   "id": "f10fb009cc63b265",
   "outputs": [],
   "execution_count": 476
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Less Negative than -0.85V \"On\"",
   "id": "d7ded736fc7c9708"
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "\n",
    "while j < len(total_miles_list):\n",
    "    df, potential_col = exception_report_df(export_name_list[j], potential_col='On Potential')\n",
    "\n",
    "    if not df.empty:\n",
    "        df_crossings, df_outliers = exception_report_crossings(\n",
    "            df,\n",
    "            potential_col=potential_col,\n",
    "            threshold=Config.POTENTIAL_850\n",
    "        )\n",
    "\n",
    "        df_excel = exception_report_to_excel(\n",
    "            export_name_list[j],\n",
    "            df_crossings,\n",
    "            total_miles_list[j],\n",
    "            'Less Negative than -0.85V (On)'\n",
    "        )\n",
    "\n",
    "        # Store df it exists\n",
    "        if not df_excel.empty:\n",
    "            dfs[('-0.85V (On)(Report)', export_name_list[j])] = df_excel\n",
    "\n",
    "    # Counter\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:06.950145Z",
     "start_time": "2025-08-11T21:13:06.792378Z"
    }
   },
   "id": "d201b6c3f7a23dec",
   "outputs": [],
   "execution_count": 477
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Less Negative than -0.85V \"Off\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44fcf58163fa0d80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.076023Z",
     "start_time": "2025-08-11T21:13:06.950937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "\n",
    "while j < len(total_miles_list):\n",
    "    df, potential_col = exception_report_df(export_name_list[j], potential_col='Off Potential')\n",
    "\n",
    "    if not df.empty:\n",
    "        df_crossings, df_outliers = exception_report_crossings(\n",
    "            df,\n",
    "            potential_col=potential_col,\n",
    "            threshold=Config.POTENTIAL_850\n",
    "        )\n",
    "\n",
    "        df_excel = exception_report_to_excel(\n",
    "            export_name_list[j],\n",
    "            df_crossings,\n",
    "            total_miles_list[j],\n",
    "            'Less Negative than -0.85V (Off)'\n",
    "        )\n",
    "\n",
    "        # Store df it exists\n",
    "        if not df_excel.empty:\n",
    "            dfs[('-0.85V (Off)(Report)', export_name_list[j])] = df_excel\n",
    "\n",
    "    # Counter\n",
    "    j += 1"
   ],
   "id": "f6698a79ff5c2b95",
   "outputs": [],
   "execution_count": 478
  },
  {
   "cell_type": "markdown",
   "source": [
    "## More Negative than -1.2V \"Off\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d534a06aab892b"
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "\n",
    "while j < len(total_miles_list):\n",
    "    df, potential_col = exception_report_df(export_name_list[j], potential_col='Off Potential')\n",
    "\n",
    "    if not df.empty:\n",
    "        df_crossings, df_outliers = exception_report_crossings(\n",
    "            df,\n",
    "            potential_col=potential_col,\n",
    "            threshold=Config.POTENTIAL_1200\n",
    "        )\n",
    "\n",
    "        df_excel = exception_report_to_excel(\n",
    "            export_name_list[j],\n",
    "            df_crossings,\n",
    "            total_miles_list[j],\n",
    "            'More Negative than -1.2V (Off)'\n",
    "        )\n",
    "\n",
    "        # Store df it exists\n",
    "        if not df_excel.empty:\n",
    "            dfs[('-1.2V (Off)(Report)', export_name_list[j])] = df_excel\n",
    "\n",
    "    # Counter\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.191680Z",
     "start_time": "2025-08-11T21:13:07.076659Z"
    }
   },
   "id": "e4abc32eac968e75",
   "outputs": [],
   "execution_count": 479
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ACVG Report",
   "id": "531d53becd0e2fd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.194273Z",
     "start_time": "2025-08-11T21:13:07.192454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not config.PLOT_3D:\n",
    "    # Dataframe\n",
    "    df_cis_acvg = pd.read_csv(DATA_DIR / original_data_list[0])\n",
    "    df_cis_acvg = df_cis_acvg[df_cis_acvg['ACVG Indication (dBV)'] != 0]\n",
    "    df_cis_acvg = df_cis_acvg[\n",
    "        ['Station', 'Stationing (ft)', 'Longitude', 'Latitude',\n",
    "         'On Potential', 'Off Potential',\n",
    "         'ACVG Indication (dBV)', 'ACVG Notes']\n",
    "    ].reset_index(drop=True)"
   ],
   "id": "dd01451260a6954d",
   "outputs": [],
   "execution_count": 480
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.196574Z",
     "start_time": "2025-08-11T21:13:07.195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Borders\n",
    "thin = Side(border_style='thin', color='000000')\n",
    "white_border = Side(border_style='thin', color='FFFFFF')"
   ],
   "id": "fb5a931a462f084c",
   "outputs": [],
   "execution_count": 481
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## -0.85V \"On\" (ACVG >= 45)",
   "id": "c1522bf6e4b156ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.200976Z",
     "start_time": "2025-08-11T21:13:07.197257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'ACVG Indication (dBV)' in df_cis.columns:\n",
    "    # Dataframe\n",
    "    df_cis_acvg_on_45 = df_cis_acvg.copy()\n",
    "    df_cis_acvg_on_45 = df_cis_acvg_on_45[(df_cis_acvg_on_45['On Potential'] >= -0.85) &\n",
    "                                          (df_cis_acvg_on_45['ACVG Indication (dBV)'] >= 45.0)]\n",
    "    df_cis_acvg_on_45 = df_cis_acvg_on_45.drop(columns='Station')\n",
    "    last_index = df_cis_acvg_on_45.reset_index().last_valid_index()\n",
    "\n",
    "    # Export to excel\n",
    "    acvg_excel = f\"ACVG Report ({export_name_list[0]}).xlsx\"\n",
    "    with pd.ExcelWriter(OUTPUT_DIR / acvg_excel, mode='w',\n",
    "                        engine='openpyxl') as writer:\n",
    "        df_cis_acvg_on_45.to_excel(writer, sheet_name='-0.85V (On)(ACVG 45)', index_label='ID')\n",
    "\n",
    "    # Modify sheet\n",
    "    wb = load_workbook(OUTPUT_DIR / acvg_excel)\n",
    "    sheet = wb['-0.85V (On)(ACVG 45)']\n",
    "\n",
    "    # Rename ACVG column\n",
    "    sheet.cell(1, 7).value = 'ACVG (dBV)'\n",
    "\n",
    "    # Formatting\n",
    "    i = 0\n",
    "\n",
    "    while i < last_index + 2:\n",
    "        for c in sheet['A1:H' + str(last_index + 2)][i]:\n",
    "            c.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            c.font = Font(bold=False)\n",
    "            c.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Header\n",
    "    for i in range(1, 9):\n",
    "        sheet.cell(1, i).font = Font(bold=True)\n",
    "\n",
    "    # Column widths\n",
    "    for col in 'ABCDEFG':\n",
    "        sheet.column_dimensions[col].width = 15\n",
    "\n",
    "    sheet.column_dimensions['H'].width = 50\n",
    "\n",
    "    # Save to excel\n",
    "    wb.save(OUTPUT_DIR / acvg_excel)"
   ],
   "id": "f0123f4de1586ce0",
   "outputs": [],
   "execution_count": 482
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## -0.85V \"On\" (ACVG >= 60)",
   "id": "f478113dbec326d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.204916Z",
     "start_time": "2025-08-11T21:13:07.201636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'ACVG Indication (dBV)' in df_cis.columns:\n",
    "    # Dataframe\n",
    "    df_cis_acvg_on_60 = df_cis_acvg.copy()\n",
    "    df_cis_acvg_on_60 = df_cis_acvg_on_60[(df_cis_acvg_on_60['On Potential'] >= -0.85) &\n",
    "                                          (df_cis_acvg_on_60['ACVG Indication (dBV)'] >= 60.0)]\n",
    "    df_cis_acvg_on_60 = df_cis_acvg_on_60.drop(columns='Station')\n",
    "    last_index = df_cis_acvg_on_60.reset_index().last_valid_index()\n",
    "\n",
    "    # Save to excel\n",
    "    with pd.ExcelWriter(OUTPUT_DIR / acvg_excel, mode='a',\n",
    "                        engine='openpyxl') as writer:\n",
    "        df_cis_acvg_on_60.to_excel(writer, sheet_name='-0.85V (On)(ACVG 60)', index_label='ID')\n",
    "\n",
    "    # Modify sheet\n",
    "    wb = load_workbook(OUTPUT_DIR / acvg_excel)\n",
    "    sheet = wb['-0.85V (On)(ACVG 60)']\n",
    "\n",
    "    # Rename ACVG column\n",
    "    sheet.cell(1, 7).value = 'ACVG (dBV)'\n",
    "\n",
    "    # Formatting\n",
    "    i = 0\n",
    "\n",
    "    while i < last_index + 2:\n",
    "        for c in sheet['A1:H' + str(last_index + 2)][i]:\n",
    "            c.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            c.font = Font(bold=False)\n",
    "            c.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Header\n",
    "    for i in range(1, 9):\n",
    "        sheet.cell(1, i).font = Font(bold=True)\n",
    "\n",
    "    # Column widths\n",
    "    for col in 'ABCDEFG':\n",
    "        sheet.column_dimensions[col].width = 15\n",
    "\n",
    "    sheet.column_dimensions['H'].width = 50\n",
    "\n",
    "    # Save to excel\n",
    "    wb.save(OUTPUT_DIR / acvg_excel)"
   ],
   "id": "69d14b5067b8646f",
   "outputs": [],
   "execution_count": 483
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## -0.85V \"Off\" (ACVG >= 45)",
   "id": "d3586c8aeea4378"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.208762Z",
     "start_time": "2025-08-11T21:13:07.205526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'ACVG Indication (dBV)' in df_cis.columns:\n",
    "    # Dataframe\n",
    "    df_cis_acvg_off_45 = df_cis_acvg.copy()\n",
    "    df_cis_acvg_off_45 = df_cis_acvg_off_45[(df_cis_acvg_off_45['Off Potential'] >= -0.85) &\n",
    "                                            (df_cis_acvg_off_45['ACVG Indication (dBV)'] >= 45.0)]\n",
    "    df_cis_acvg_off_45 = df_cis_acvg_off_45.drop(columns='Station')\n",
    "    last_index = df_cis_acvg_off_45.reset_index().last_valid_index()\n",
    "\n",
    "    # Save to excel\n",
    "    with pd.ExcelWriter(OUTPUT_DIR / acvg_excel, mode='a',\n",
    "                        engine='openpyxl') as writer:\n",
    "        df_cis_acvg_off_45.to_excel(writer, sheet_name='-0.85V (Off)(ACVG 45)', index_label='ID')\n",
    "\n",
    "    # Modify sheet\n",
    "    wb = load_workbook(OUTPUT_DIR / acvg_excel)\n",
    "    sheet = wb['-0.85V (Off)(ACVG 45)']\n",
    "\n",
    "    # Rename ACVG column\n",
    "    sheet.cell(1, 7).value = 'ACVG (dBV)'\n",
    "\n",
    "    # Formatting\n",
    "    i = 0\n",
    "\n",
    "    while i < last_index + 2:\n",
    "        for c in sheet['A1:H' + str(last_index + 2)][i]:\n",
    "            c.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            c.font = Font(bold=False)\n",
    "            c.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Header\n",
    "    for i in range(1, 9):\n",
    "        sheet.cell(1, i).font = Font(bold=True)\n",
    "\n",
    "    # Column widths\n",
    "    for col in 'ABCDEFG':\n",
    "        sheet.column_dimensions[col].width = 15\n",
    "\n",
    "    sheet.column_dimensions['H'].width = 50\n",
    "\n",
    "    # Save to excel\n",
    "    wb.save(OUTPUT_DIR / acvg_excel)"
   ],
   "id": "e7592bffab933f2f",
   "outputs": [],
   "execution_count": 484
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## -0.85V \"Off\" (ACVG >= 60)",
   "id": "cb7460d7360e74a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.212852Z",
     "start_time": "2025-08-11T21:13:07.209453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'ACVG Indication (dBV)' in df_cis.columns:\n",
    "    # Dataframe\n",
    "    df_cis_acvg_off_60 = df_cis_acvg.copy()\n",
    "    df_cis_acvg_off_60 = df_cis_acvg_off_60[(df_cis_acvg_off_60['Off Potential'] >= -0.85) &\n",
    "                                            (df_cis_acvg_off_60['ACVG Indication (dBV)'] >= 60.0)]\n",
    "    df_cis_acvg_off_60 = df_cis_acvg_off_60.drop(columns='Station')\n",
    "    last_index = df_cis_acvg_off_60.reset_index().last_valid_index()\n",
    "\n",
    "    # Save to excel\n",
    "    with pd.ExcelWriter(OUTPUT_DIR / acvg_excel, mode='a',\n",
    "                        engine='openpyxl') as writer:\n",
    "        df_cis_acvg_off_60.to_excel(writer, sheet_name='-0.85V (Off)(ACVG 60)', index_label='ID')\n",
    "\n",
    "    # Modify sheet\n",
    "    wb = load_workbook(OUTPUT_DIR / acvg_excel)\n",
    "    sheet = wb['-0.85V (Off)(ACVG 60)']\n",
    "\n",
    "    # Rename ACVG column\n",
    "    sheet.cell(1, 7).value = 'ACVG (dBV)'\n",
    "\n",
    "    # Formatting\n",
    "    i = 0\n",
    "\n",
    "    while i < last_index + 2:\n",
    "        for c in sheet['A1:H' + str(last_index + 2)][i]:\n",
    "            c.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            c.font = Font(bold=False)\n",
    "            c.border = Border(top=thin, left=thin, right=thin, bottom=thin)\n",
    "\n",
    "        # Counters\n",
    "        i += 1\n",
    "\n",
    "    # Header\n",
    "    for i in range(1, 9):\n",
    "        sheet.cell(1, i).font = Font(bold=True)\n",
    "\n",
    "    # Column widths\n",
    "    for col in 'ABCDEFG':\n",
    "        sheet.column_dimensions[col].width = 15\n",
    "\n",
    "    sheet.column_dimensions['H'].width = 50\n",
    "\n",
    "    # Save to excel\n",
    "    wb.save(OUTPUT_DIR / acvg_excel)"
   ],
   "id": "25b0f9a73938cd79",
   "outputs": [],
   "execution_count": 485
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Severity Matrix",
   "id": "d41b4ea051b9e63f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.214807Z",
     "start_time": "2025-08-11T21:13:07.213508Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO: Deal with this when there is no acvg, etc.",
   "id": "8489a1e49233306c",
   "outputs": [],
   "execution_count": 486
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.216861Z",
     "start_time": "2025-08-11T21:13:07.215347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Dataframe\n",
    "# df_cis_matrix = df_cis.copy()\n",
    "# df_cis_matrix = df_cis_matrix[['Station', 'Stationing (ft)', 'On Potential', 'Off Potential',\n",
    "#                                'Comments', 'Longitude', 'Latitude',\n",
    "#                                'ACVG Indication (dBV)', 'ACVG Notes',\n",
    "#                                'PCM Data (Amps)', 'PCM % Change']].reset_index(drop=True)\n",
    "# df_cis_matrix['ACVG Severity'] = 0\n",
    "# df_cis_matrix['PCM Severity'] = 0\n",
    "# df_cis_matrix['Total Severity'] = 0"
   ],
   "id": "a933d7103ecb9f7e",
   "outputs": [],
   "execution_count": 487
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.218862Z",
     "start_time": "2025-08-11T21:13:07.217461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # ACVG\n",
    "# df_cis_matrix.loc[(df_cis_matrix['ACVG Indication (dBV)'] < 50), 'ACVG Severity'] = 0\n",
    "# df_cis_matrix.loc[(df_cis_matrix['ACVG Indication (dBV)'] >= 50) & (\n",
    "#         df_cis_matrix['ACVG Indication (dBV)'] < 66), 'ACVG Severity'] = 1\n",
    "# df_cis_matrix.loc[(df_cis_matrix['ACVG Indication (dBV)'] >= 66) & (\n",
    "#         df_cis_matrix['ACVG Indication (dBV)'] < 81), 'ACVG Severity'] = 4\n",
    "# df_cis_matrix.loc[(df_cis_matrix['ACVG Indication (dBV)'] >= 81), 'ACVG Severity'] = 6\n",
    "# # df_cis_matrix = df_cis_matrix[df_cis_matrix['ACVG Indication (dBV)'] != 0]"
   ],
   "id": "f8f4ea9d080a7f24",
   "outputs": [],
   "execution_count": 488
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.222960Z",
     "start_time": "2025-08-11T21:13:07.221576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # PCM\n",
    "# df_cis_matrix.loc[(df_cis_matrix['PCM % Change'] >= 0) & (\n",
    "#         df_cis_matrix['PCM % Change'] < 10), 'PCM Severity'] = 1\n",
    "# df_cis_matrix.loc[(df_cis_matrix['PCM % Change'] >= 10) & (\n",
    "#         df_cis_matrix['PCM % Change'] < 20), 'PCM Severity'] = 2\n",
    "# df_cis_matrix.loc[(df_cis_matrix['PCM % Change'] >= 20), 'PCM Severity'] = 3\n",
    "# # df_cis_matrix = df_cis_matrix[df_cis_matrix['PCM % Change'] != 0]"
   ],
   "id": "40b53d6ee8743486",
   "outputs": [],
   "execution_count": 489
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Log File",
   "id": "bc95f5599cb93eb3"
  },
  {
   "cell_type": "code",
   "source": [
    "j = 0  # Loop counter for '.csv' files\n",
    "\n",
    "# Current date and time\n",
    "e = datetime.datetime.now()\n",
    "execution_time = time.time() - start_time\n",
    "minutes, seconds = divmod(execution_time, 60)\n",
    "\n",
    "while j < len(original_data_list):\n",
    "    total_rows_dropped = log_dict[export_name_list[j]]['Dataframe']['Rows Dropped']\n",
    "    mean = log_dict[export_name_list[j]]['Statistics']['Mean']\n",
    "    mode = log_dict[export_name_list[j]]['Statistics']['Mode']\n",
    "    std = log_dict[export_name_list[j]]['Statistics']['Std']\n",
    "    total_count = log_dict[export_name_list[j]]['Statistics']['Total Count']\n",
    "    cutoff_count = log_dict[export_name_list[j]]['Statistics']['Cutoff Count']\n",
    "    outliers_count = log_dict[export_name_list[j]]['Statistics']['Outliers Count']\n",
    "    duplicates_count = log_dict[export_name_list[j]]['Statistics']['Duplicates Count']\n",
    "    on_measurements = log_dict[export_name_list[j]]['Measurements']['On']\n",
    "    off_measurements = log_dict[export_name_list[j]]['Measurements']['Off']\n",
    "\n",
    "    # Modify log file with information of interest\n",
    "    with open(LOGS_DIR / f\"{export_name_list[j]}(Log).txt\", 'w') as f:\n",
    "        f.write('-' * 75 + '\\n')\n",
    "        f.write(f\"GPS DATA ({config.LOWER_CUTOFF}ft to {config.UPPER_CUTOFF}ft)\\n\")\n",
    "        f.write('-' * 75 + '\\n\\n')\n",
    "        f.write(f\"Rows Dropped (Missing GPS): \")\n",
    "        f.write(f\"{total_rows_dropped}\\n\")\n",
    "        f.write(f\"Count: {total_count}\\n\")\n",
    "        f.write(f\"Cutoff Count: {total_count - cutoff_count}\\n\")\n",
    "        f.write(f\"Consistency: {round(cutoff_count / total_count * 100, 2)}%\\n\")\n",
    "        f.write(f\"Mean: {round(mean, 3)}\\n\")\n",
    "        f.write(f\"Mode: {mode}\\n\")\n",
    "        f.write(f\"Standard Deviation: {round(std, 3)}\\n\")\n",
    "\n",
    "        if mean - std * 2.576 <= 0:\n",
    "            f.write(f\"99% Confidence Interval: {0} to {round(mean + std * 2.576, 3)}\\n\")\n",
    "\n",
    "        else:\n",
    "            f.write(f\"99% Confidence Interval: {round(mean - std * 2.576, 3)} to \"\n",
    "                    f\"{round(mean + std * 2.576, 3)}\\n\")\n",
    "\n",
    "        f.write(f\"Outliers: {outliers_count}\\n\")\n",
    "\n",
    "        if config.PLOT_3D:\n",
    "            f.write(\n",
    "                f\"Duplicated GPS Pairs: {duplicates_count}\\n\\n\")\n",
    "\n",
    "        if config.PLOT_3D:\n",
    "            f.write('-' * 75 + '\\n')\n",
    "            f.write(f\"MEASUREMENTS\\n\")\n",
    "            f.write('-' * 75 + '\\n\\n')\n",
    "            f.write(f\"On: {on_measurements}\\n\")\n",
    "            f.write(f\"Off: {off_measurements}\\n\")\n",
    "            f.write(f\"Ratio (On/Off): {round(on_measurements / off_measurements, 3)}\\n\\n\")\n",
    "\n",
    "        if config.PLOT_3D:\n",
    "            f.write('-' * 75 + '\\n')\n",
    "            f.write(f\"VARIABLES\\n\")\n",
    "            f.write('-' * 75 + '\\n\\n')\n",
    "            f.write(f\"Client: {config.CLIENT}\\n\")\n",
    "            f.write(f\"Reverse: {config.REVERSE}\\n\")\n",
    "            f.write(f\"Scale Factor: {config.SCALE_FACTOR}\\n\")\n",
    "            f.write(f\"Scale PCM: {config.SCALE_PCM}\\n\")\n",
    "            f.write(f\"Scale PCM (%): {config.SCALE_PCM_PERCENT}\\n\")\n",
    "            f.write(f\"Icon Scale: {config.ICON_SCALE}\\n\")\n",
    "            f.write(f\"Color Scheme: {config.COLOR_SCHEME}\\n\\n\")\n",
    "\n",
    "        f.write('-' * 75 + '\\n')\n",
    "        f.write(f\"EXECUTION\\n\")\n",
    "        f.write('-' * 75 + '\\n\\n')\n",
    "        f.write(f\"User: {socket.gethostname()}\\n\")\n",
    "        f.write(f'{e.strftime(\"%b, %d, %Y\")}, {e.hour:02d}:{e.minute:02d}:{e.second:02d}')\n",
    "        f.write('\\n')\n",
    "        f.write(f\"Execution Time ({int(minutes)} min {int(seconds)} sec)\")\n",
    "\n",
    "    # Counter\n",
    "    j += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T21:13:07.230195Z",
     "start_time": "2025-08-11T21:13:07.223526Z"
    }
   },
   "id": "97a06a50780ee69b",
   "outputs": [],
   "execution_count": 490
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
